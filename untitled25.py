# -*- coding: utf-8 -*-
"""Untitled25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tKNSEJ01dd81n2Mt7uUBT2fsLZ5yHYtu
"""

import pandas as pd
import numpy as np

df = pd.read_csv("/content/Mall_Customers.csv")
df.head()

# Dataset shape and types
print("Shape:", df.shape)
print("\nData Types:\n", df.dtypes)

# Check for missing values
print("\nMissing Values:\n", df.isnull().sum())

# Drop unnecessary 'CustomerID' column
df.drop('CustomerID', axis=1, inplace=True)

# Preview cleaned data
df.head()

# Import visualization libraries
import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")

# Plot 1: Gender distribution
plt.figure(figsize=(6,4))
sns.countplot(x='Genre', data=df)
plt.title("Gender Distribution")
plt.show()

# Plot 2: Age distribution
plt.figure(figsize=(6,4))
sns.histplot(df['Age'], kde=True, bins=15, color='skyblue')
plt.title("Age Distribution")
plt.show()

# Plot 3: Annual Income distribution
plt.figure(figsize=(6,4))
sns.histplot(df['Annual Income (k$)'], kde=True, bins=15, color='orange')
plt.title("Annual Income Distribution")
plt.show()

# Plot 4: Spending Score distribution
plt.figure(figsize=(6,4))
sns.histplot(df['Spending Score (1-100)'], kde=True, bins=15, color='green')
plt.title("Spending Score Distribution")
plt.show()

from sklearn.preprocessing import StandardScaler

# Step 1: Select relevant numerical features
X = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]

# Step 2: Scale the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Show scaled data (optional)
X_scaled[:5]

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Step 1: Try k values from 1 to 10
inertia = []
K = range(1, 11)

for k in K:
    model = KMeans(n_clusters=k, random_state=42)
    model.fit(X_scaled)
    inertia.append(model.inertia_)

# Step 2: Plot Elbow Curve
plt.figure(figsize=(6,4))
plt.plot(K, inertia, 'bo-')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal k')
plt.show()

# Step 1: Fit KMeans with optimal k = 5
kmeans = KMeans(n_clusters=5, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Step 2: Add cluster labels to original dataframe
df['Cluster'] = clusters

# Step 3: Preview updated data
df.head()

# Step 4: Scatter plot of clusters
plt.figure(figsize=(8,6))
sns.scatterplot(
    x=df['Annual Income (k$)'],
    y=df['Spending Score (1-100)'],
    hue=df['Cluster'],
    palette='Set1',
    s=100
)
plt.title('Customer Segments Based on Income and Spending Score')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend(title='Cluster')
plt.show()

import scipy.cluster.hierarchy as sch
from sklearn.cluster import AgglomerativeClustering

# Step 1: Plot dendrogram
plt.figure(figsize=(10, 5))
dendrogram = sch.dendrogram(sch.linkage(X_scaled, method='ward'))
plt.title("Dendrogram for Hierarchical Clustering")
plt.xlabel("Customers")
plt.ylabel("Euclidean distances")
plt.show()

# Step 2: Fit Hierarchical Clustering (fixed version)
hc = AgglomerativeClustering(n_clusters=5, metric='euclidean', linkage='ward')
df['HC_Cluster'] = hc.fit_predict(X_scaled)

# Step 3: Visualize clusters
plt.figure(figsize=(8,6))
sns.scatterplot(x=df['Annual Income (k$)'], y=df['Spending Score (1-100)'],
                hue=df['HC_Cluster'], palette='tab10', s=100)
plt.title("Hierarchical Clustering Result")
plt.show()

from sklearn.decomposition import PCA

# Apply PCA to reduce dimensions to 2D
pca = PCA(n_components=2)
pca_result = pca.fit_transform(X_scaled)

# Plot PCA results with cluster coloring
plt.figure(figsize=(8,6))
sns.scatterplot(x=pca_result[:,0], y=pca_result[:,1], hue=df['Cluster'], palette='Set1', s=100)
plt.title("PCA - KMeans Clusters in 2D")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.show()

# Optional - Save the KMeans model
import joblib
joblib.dump(kmeans, 'kmeans_customer_segmentation.pkl')